# Awesome Adversarial Attack and Defense in NLP[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
  <img width="250" src="https://camo.githubusercontent.com/1131548cf666e1150ebd2a52f44776d539f06324/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f6d61737465722f6d656469612f6c6f676f2e737667" "Awesome!">
</p>

A curated list of adversarial attack and defense in NLP. :-)

## Contributing
Please feel free to send me [pull requests](https://github.com/zhjohnchan/awesome-adversarial-attack-and-defense-in-nlp/pulls) or email (chihung.chan@outlook.com) to add links.

## Table of Contents
- [Papers](#papers)
  - [Survey](#survey)
  - [Research Paper](#research-paper)

## Papers
### Research Paper
|   Year | Venue    | Title                                                                                                                                                                         |
|-------:|:---------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|   2008 | EMNLP    | [Attacking Decipherment Problems Optimally with Low-Order N-gram Models](https://aclanthology.org/D08-1085.pdf)                                                               |
|   2012 | ACL      | [Attacking Parsing Bottlenecks with Unlabeled Data and Relevant Factorizations](https://aclanthology.org/P12-1081.pdf)                                                        |
|   2013 | NAACL    | [Supersense Tagging for Arabic: the MT-in-the-Middle Attack](https://aclanthology.org/N13-1076.pdf)                                                                           |
|   2017 | EMNLP    | [Identifying attack and support argumentative relations using deep learning](https://aclanthology.org/D17-1144.pdf)                                                           |
|   2018 | ACL      | [Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning](https://aclanthology.org/P18-1241.pdf)                               |
|   2018 | EMNLP    | [Extractive Adversarial Networks: High-Recall Explanations for Identifying Personal Attacks in Social Media Posts](https://aclanthology.org/D18-1386.pdf)                     |
|   2018 | NAACL    | [Detecting Denial-of-Service Attacks from Social Media Text: Applying NLP to Computer Security](https://aclanthology.org/N18-1147.pdf)                                        |
|   2018 | COLING   | [Enhancing Cohesion and Coherence of Fake Text to Improve Believability for Deceiving Cyber Attackers](https://aclanthology.org/W18-4104.pdf)                                 |
|   2019 | ACL      | [Adversarial Attack on Sentiment Classification](https://aclanthology.org/W19-3653.pdf)                                                                                       |
|   2019 | ACL      | [Adversarial Attack on Sentiment Classification](https://aclanthology.org/W19-4824.pdf)                                                                                       |
|   2019 | EMNLP    | [Universal Adversarial Triggers for Attacking and Analyzing NLP](https://aclanthology.org/D19-1221.pdf)                                                                       |
|   2019 | EMNLP    | [Evaluating adversarial attacks against multiple fact verification systems](https://aclanthology.org/D19-1292.pdf)                                                            |
|   2019 | EMNLP    | [Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack](https://aclanthology.org/D19-1461.pdf)                                               |
|   2019 | EMNLP    | [Learning to Discriminate Perturbations for Blocking Adversarial Attacks in Text Classification](https://aclanthology.org/D19-1496.pdf)                                       |
|   2019 | EMNLP    | [GEM: Generative Enhanced Model for adversarial attacks](https://aclanthology.org/D19-6604.pdf)                                                                               |
|   2019 | NAACL    | [White-to-Black: Efficient Distillation of Black-Box Adversarial Attacks](https://aclanthology.org/N19-1139.pdf)                                                              |
|   2019 | NAACL    | [Text Processing Like Humans Do: Visually Attacking and Shielding NLP Systems](https://aclanthology.org/N19-1165.pdf)                                                         |
|   2020 | ACL      | [Weight Poisoning Attacks on Pretrained Models](https://aclanthology.org/2020.acl-main.249.pdf)                                                                               |
|   2020 | ACL      | [Word-level Textual Adversarial Attacking as Combinatorial Optimization](https://aclanthology.org/2020.acl-main.540.pdf)                                                      |
|   2020 | EMNLP    | [Detecting Attackable Sentences in Arguments](https://aclanthology.org/2020.emnlp-main.1.pdf)                                                                                 |
|   2020 | EMNLP    | [Adversarial Attack and Defense of Structured Prediction Models](https://aclanthology.org/2020.emnlp-main.182.pdf)                                                            |
|   2020 | EMNLP    | [Imitation Attacks and Defenses for Black-box Machine Translation Systems](https://aclanthology.org/2020.emnlp-main.446.pdf)                                                  |
|   2020 | EMNLP    | [T3: Tree-Autoencoder Constrained Adversarial Text Generation for Targeted Attack](https://aclanthology.org/2020.emnlp-main.495.pdf)                                          |
|   2020 | EMNLP    | [BERT-ATTACK: Adversarial Attack Against BERT Using BERT](https://aclanthology.org/2020.emnlp-main.500.pdf)                                                                   |
|   2020 | EMNLP    | [Detecting Word Sense Disambiguation Biases in Machine Translation for Model-Agnostic Adversarial Attacks](https://aclanthology.org/2020.emnlp-main.616.pdf)                  |
|   2020 | EMNLP    | [TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP](https://aclanthology.org/2020.emnlp-demos.16.pdf)                       |
|   2020 | EMNLP    | [Leveraging Extracted Model Adversaries for Improved Black Box Attacks](https://aclanthology.org/2020.blackboxnlp-1.6.pdf)                                                    |
|   2020 | EMNLP    | [Evaluation of Coreference Resolution Systems Under Adversarial Attacks](https://aclanthology.org/2020.codi-1.16.pdf)                                                         |
|   2020 | EMNLP    | [Generalization to Mitigate Synonym Substitution Attacks](https://aclanthology.org/2020.deelio-1.3.pdf)                                                                       |
|   2020 | EMNLP    | [Poison Attacks against Text Datasets with Conditional Adversarially Regularized Autoencoder](https://aclanthology.org/2020.findings-emnlp.373.pdf)                           |
|   2020 | EMNLP    | [TextAttack: Lessons learned in designing Python frameworks for NLP](https://aclanthology.org/2020.nlposs-1.18.pdf)                                                           |
|   2020 | COLING   | [Enhancing Neural Models with Vulnerability via Adversarial Attack](https://aclanthology.org/2020.coling-main.98.pdf)                                                         |
|   2020 | COLING   | [Contrastive Zero-Shot Learning for Cross-Domain Slot Filling with Adversarial Attack](https://aclanthology.org/2020.coling-main.126.pdf)                                     |
|   2020 | COLING   | [A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples](https://aclanthology.org/2020.coling-main.585.pdf)                                          |
|   2020 | AACL     | [From Hero to Zéroe: A Benchmark of Low-Level Adversarial Attacks](https://aclanthology.org/2020.aacl-main.79.pdf)                                                            |
|   2020 | Findings | [Poison Attacks against Text Datasets with Conditional Adversarially Regularized Autoencoder](https://aclanthology.org/2020.findings-emnlp.373.pdf)                           |
|   2020 | TACL     | [Membership Inference Attacks on Sequence-to-Sequence Models: Is My Data In Your Machine Translation System?](https://aclanthology.org/2020.tacl-1.4.pdf)                     |
|   2021 | ACL      | [Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger](https://aclanthology.org/2021.acl-long.37.pdf)                                                     |
|   2021 | ACL      | [A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal Trigger’s Adversarial Attacks](https://aclanthology.org/2021.acl-long.296.pdf)                             |
|   2021 | ACL      | [Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution](https://aclanthology.org/2021.acl-long.377.pdf)                                         |
|   2021 | ACL      | [Defense against Synonym Substitution-based Adversarial Attacks via Dirichlet Neighborhood Ensemble](https://aclanthology.org/2021.acl-long.426.pdf)                          |
|   2021 | ACL      | [Rethinking Stealthiness of Backdoor Attack against NLP Models](https://aclanthology.org/2021.acl-long.431.pdf)                                                               |
|   2021 | ACL      | [Using Adversarial Attacks to Reveal the Statistical Bias in Machine Reading Comprehension Models](https://aclanthology.org/2021.acl-short.43.pdf)                            |
|   2021 | ACL      | [An Empirical Study on Adversarial Attack on NMT: Languages and Positions Matter](https://aclanthology.org/2021.acl-short.58.pdf)                                             |
|   2021 | ACL      | [OpenAttack: An Open-source Textual Adversarial Attack Toolkit](https://aclanthology.org/2021.acl-demo.43.pdf)                                                                |
|   2021 | NAACL    | [Concealed Data Poisoning Attacks on NLP Models](https://aclanthology.org/2021.naacl-main.13.pdf)                                                                             |
|   2021 | NAACL    | [Certified Robustness to Word Substitution Attack with Differential Privacy](https://aclanthology.org/2021.naacl-main.87.pdf)                                                 |
|   2021 | NAACL    | [Universal Adversarial Attacks with Natural Triggers for Text Classification](https://aclanthology.org/2021.naacl-main.291.pdf)                                               |
|   2021 | NAACL    | [Dynamically Disentangling Social Bias from Task-Oriented Representations with Adversarial Attack](https://aclanthology.org/2021.naacl-main.293.pdf)                          |
|   2021 | NAACL    | [Grey-box Adversarial Attack And Defence For Sentiment Classification](https://aclanthology.org/2021.naacl-main.321.pdf)                                                      |
|   2021 | NAACL    | [Contextualized Perturbation for Textual Adversarial Attack](https://aclanthology.org/2021.naacl-main.400.pdf)                                                                |
|   2021 | EACL     | [Adversarial Stylometry in the Wild: Transferable Lexical Substitution Attacks on Author Profiling](https://aclanthology.org/2021.eacl-main.203.pdf)                          |
|   2021 | Findings | [OutFlip: Generating Examples for Unknown Intent Detection with Natural Language Attack](https://aclanthology.org/2021.findings-acl.45.pdf)                                   |
|   2021 | Findings | [Putting words into the system’s mouth: A targeted attack on neural machine translation using monolingual data poisoning](https://aclanthology.org/2021.findings-acl.127.pdf) |
|   2021 | Findings | [BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks](https://aclanthology.org/2021.findings-acl.141.pdf)       |
|   2021 | Findings | [Counter-Argument Generation by Attacking Weak Premises](https://aclanthology.org/2021.findings-acl.159.pdf)                                                                  |

## Licenses

[![CC0](http://i.creativecommons.org/p/zero/1.0/88x31.png)](http://creativecommons.org/publicdomain/zero/1.0/)

To the extent possible under law, [Zhihong Chen](https://github.com/zhjohnchan) has waived all copyright and related or neighboring rights to this work.
